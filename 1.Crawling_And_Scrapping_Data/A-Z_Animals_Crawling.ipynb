{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ceeed37",
   "metadata": {},
   "source": [
    "<font size=\"10\">\n",
    "    <b>\n",
    "        A-Z Animals Site Crawling \n",
    "        <b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af446c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup  \n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bca722",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "    <b>\n",
    "        Opening the downloaded site page \n",
    "        <b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fea0bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://a-z-animals.com/animals/\"\n",
    "param = \"./Data/\"\n",
    "siteName =\"All Animals A-Z List - Animal Names _ AZ Animals.html\"\n",
    "soup = BeautifulSoup(open(param + siteName), \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bd60c3",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "    <b>\n",
    "        Getting each animal's page link and creating a links data frame \n",
    "        <b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae37d539",
   "metadata": {},
   "outputs": [],
   "source": [
    "linksOfAnimalPages=list()\n",
    "listOfAnimals=soup.find_all(\"li\",attrs={\"class\":\"list-item col-md-4 col-sm-6\"})\n",
    "\n",
    "for row in listOfAnimals:\n",
    "    a_tag=row.find_all(\"a\")\n",
    "    \n",
    "    for a_rows in a_tag:\n",
    "        linksOfAnimalPages.append(a_rows.get('href'))\n",
    "        \n",
    "animal_links_df = pd.DataFrame({\"link_for_Animal_page\":linksOfAnimalPages})\n",
    "animal_links_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e557d5",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "    <b>\n",
    "        Function to crawl each link and get the animal's data into lists and merge them into a data frame to return\n",
    "        <b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e7d961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeDfByCrawlingAToZAnimalz(link):\n",
    "    \n",
    "    property_names = list()\n",
    "    property_values = list()\n",
    "    html = requests.get(link)\n",
    "    soup = BeautifulSoup(html.content,\"html.parser\")\n",
    "    div_tag = soup.find_all(\"div\",attrs={\"class\":\"row animal-facts-box\"})\n",
    "\n",
    "    if(len(div_tag) != 0):\n",
    "        dt_tag = div_tag[0].find_all(\"dt\"),div_tag[1].find_all(\"dt\")\n",
    "        dd_tag = div_tag[0].find_all(\"dd\"),div_tag[1].find_all(\"dd\")\n",
    "        Conservation_tag = div_tag[0].find(\"li\")\n",
    "        li_tag = div_tag[0].find_all(\"li\")\n",
    "\n",
    "        property_names.append(\"Conservation Status\")\n",
    "        property_names.append(\"Locations\")\n",
    "        for index in range(0,2):\n",
    "            for rows in dt_tag[index]:\n",
    "                for row_a in rows:\n",
    "                    property_names.append(row_a.get_text())\n",
    "\n",
    "        if(len(li_tag)>2):\n",
    "            locations = list()\n",
    "            \n",
    "            for index in range(1,len(li_tag)):\n",
    "                locations.append(li_tag[index].get_text())\n",
    "            locations_tuple = tuple(locations)\n",
    "            property_values.append(li_tag[0].get_text())\n",
    "            property_values.append(locations_tuple)\n",
    "            for index in range(0,2):\n",
    "                for rows in (dd_tag[index]):\n",
    "                    property_values.append(rows.get_text())     \n",
    "                    \n",
    "        elif(len(li_tag) == 2):\n",
    "            for index in range(0,2):            \n",
    "                property_values.append(li_tag[index].get_text())  \n",
    "            for index in range(0,2):\n",
    "                for rows in (dd_tag[index]):\n",
    "                    property_values.append(rows.get_text())\n",
    "\n",
    "        if(len(li_tag)>=2):\n",
    "            df_range = len(property_names)\n",
    "            df = pd.DataFrame([range(df_range)])\n",
    "            df.columns = property_names\n",
    "            df.loc[0] = property_values\n",
    "            return df\n",
    "        \n",
    "    df_empty = pd.DataFrame({'A' : []})\n",
    "    return df_empty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b622bc",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "    <b>\n",
    "        Creating the full data frame by appending each animal df\n",
    "        <b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08be97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = MakeDfByCrawlingAToZAnimalz(animal_links_df.iloc[0][0])\n",
    "for i in range(1,len(animal_links_df)):\n",
    "    dfi = MakeDfByCrawlingAToZAnimalz(animal_links_df.iloc[i][0])\n",
    "    if(not dfi.empty):\n",
    "        df = df.append([dfi])\n",
    "        \n",
    "rows = len(df.axes[0])\n",
    "df.index = range(rows)\n",
    "#df.to_csv('C:/Users/noypr/Downloads/A-Z.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
